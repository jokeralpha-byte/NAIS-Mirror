# ============= ä¿®å¤åçš„å®Œæ•´ä»£ç  =============

import torch
import torch.nn.functional as F
from einops import rearrange
import math

def _pad_to_multiple(tensor, multiple):
    """Padåˆ°æŒ‡å®šå€æ•°"""
    T, C, H, W = tensor.shape
    pad_h = (multiple - H % multiple) % multiple
    pad_w = (multiple - W % multiple) % multiple
    if pad_h > 0 or pad_w > 0:
        tensor = F.pad(tensor, [0, pad_w, 0, pad_h])
    return tensor, (pad_h, pad_w)


def _unify_kept_patches(kept_patches, pad_value=0.0):
    """
    ç»Ÿä¸€ä¸åŒå¸§çš„kept patchesæ•°é‡
    
    Args:
        kept_patches: List[Tensor], æ¯ä¸ªshapeä¸º (N_keep_i, p*p*C)
        pad_value: paddingçš„å€¼
        
    Returns:
        unified: (T, N_keep_max, p*p*C)
        N_keeps: (T,) æ¯å¸§å®é™…ä¿ç•™çš„æ•°é‡
    """
    T = len(kept_patches)
    N_keeps = torch.tensor([kp.shape[0] for kp in kept_patches])
    N_keep_max = N_keeps.max().item()
    
    device = kept_patches[0].device
    dtype = kept_patches[0].dtype
    feature_dim = kept_patches[0].shape[1]
    
    # åˆ›å»ºç»Ÿä¸€çš„tensor
    unified = torch.full(
        (T, N_keep_max, feature_dim),
        pad_value,
        device=device,
        dtype=dtype
    )
    
    # å¡«å……æ¯å¸§çš„kept patches
    for t in range(T):
        n_keep = N_keeps[t].item()
        unified[t, :n_keep] = kept_patches[t]
    
    return unified, N_keeps


# ============= æ–¹æ³•1: ç©ºé—´ä¿åºï¼ˆä¿®å¤ç‰ˆï¼‰=============

def squeeze_spatial_order(
    patch_size=16,
    mask=None,
    pic_tensor=None
):
    """ç©ºé—´ä¿åºçš„squeeze - ä¿®å¤ç‰ˆ"""
    if mask is None:
        raise RuntimeError("è¯·ç”Ÿæˆmaskä¹‹åå†squeeze")

    T, C, H, W = pic_tensor.shape
    p = patch_size

    # 1. Pad
    padded, (pad_h, pad_w) = _pad_to_multiple(pic_tensor, p)
    h_p = (H + pad_h) // p
    w_p = (W + pad_w) // p
    patched_shape = (h_p, w_p)

    # 2. è½¬ä¸ºpatchåºåˆ—
    patches = rearrange(
        padded,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p, h=h_p, w=w_p
    )

    mask_flat = mask.reshape(T, h_p * w_p)

    # 3. æŒ‰ç©ºé—´é¡ºåºæå–patches
    kept_patches = []
    original_indices = []
    
    for t in range(T):
        indices = torch.where(mask_flat[t])[0]
        original_indices.append(indices)
        kept_patches.append(patches[t][indices])
    
    # ğŸ”¥ ç»Ÿä¸€kept patchesæ•°é‡
    kept, N_keeps = _unify_kept_patches(kept_patches)  # (T, N_keep_max, p*p*C)
    N_keep = N_keeps.max().item()

    # 4. è®¡ç®—ç´§å‡‘çŸ©å½¢
    w_new = max(1, int(math.sqrt(N_keep)))
    h_new = (N_keep + w_new - 1) // w_new
    need_pad = h_new * w_new - N_keep

    # 5. Paddingåˆ°çŸ©å½¢
    if need_pad > 0:
        pad = torch.zeros(T, need_pad, kept.shape[-1],
                        device=pic_tensor.device, dtype=pic_tensor.dtype)
        kept = torch.cat([kept, pad], dim=1)

    # 6. é‡ç»„
    squeezed = rearrange(
        kept,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_new, w=w_new, p1=p, p2=p, c=C
    )

    # 7. å…ƒæ•°æ®
    metadata = {
        'method': 'spatial_order',
        'patched_shape': patched_shape,
        'N_keep': N_keep,
        'N_keeps': N_keeps,  # ğŸ”¥ æ¯å¸§å®é™…çš„æ•°é‡
        'original_indices': original_indices,  # List[Tensor]
        'region_shape': (H, W),
        'squeezed_shape': (h_new, w_new),
    }

    return squeezed, metadata


def unsqueeze_spatial_order(
    mask=None,
    squeezed_tensor=None,
    metadata=None
):
    """ç©ºé—´ä¿åºçš„unsqueeze - ä¿®å¤ç‰ˆ"""
    if mask is None or metadata is None:
        raise RuntimeError("éœ€è¦maskå’Œmetadata")

    T, C, H_sq, W_sq = squeezed_tensor.shape
    p = 16
    
    patched_shape = metadata['patched_shape']
    N_keeps = metadata['N_keeps']  # (T,)
    original_indices = metadata['original_indices']  # List[Tensor]
    region_shape = metadata['region_shape']

    # 1. æå–patches
    patches = rearrange(
        squeezed_tensor,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p
    )

    # 2. è¿˜åŸåˆ°åŸå§‹maskä½ç½®
    h_p, w_p = patched_shape
    full = torch.zeros(T, h_p * w_p, p * p * C,
                      device=squeezed_tensor.device, 
                      dtype=squeezed_tensor.dtype)
    
    mask_flat = mask.reshape(T, h_p * w_p)
    
    # ğŸ”¥ æ¯å¸§å•ç‹¬å¤„ç†ï¼Œä½¿ç”¨æ­£ç¡®çš„N_keep
    for t in range(T):
        n_keep = N_keeps[t].item()
        valid_patches = patches[t, :n_keep]  # åªå–æœ‰æ•ˆçš„patches
        full[t, original_indices[t]] = valid_patches

    # 3. é‡ç»„
    recon = rearrange(
        full,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_p, w=w_p, p1=p, p2=p, c=C
    )

    return recon[:, :, :region_shape[0], :region_shape[1]]


# ============= æ–¹æ³•2: ç›¸ä¼¼åº¦æ’åºï¼ˆä¿®å¤ç‰ˆï¼‰=============

def squeeze_similarity_order(
    patch_size=16,
    mask=None,
    pic_tensor=None,
    sort_by='brightness'
):
    """ç›¸ä¼¼åº¦æ’åºçš„squeeze - ä¿®å¤ç‰ˆ"""
    if mask is None:
        raise RuntimeError("è¯·ç”Ÿæˆmaskä¹‹åå†squeeze")

    T, C, H, W = pic_tensor.shape
    p = patch_size

    # 1-2. Padå’Œåˆ†patch
    padded, (pad_h, pad_w) = _pad_to_multiple(pic_tensor, p)
    h_p = (H + pad_h) // p
    w_p = (W + pad_w) // p
    patched_shape = (h_p, w_p)

    patches = rearrange(
        padded,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p, h=h_p, w=w_p
    )

    mask_flat = mask.reshape(T, h_p * w_p)

    # 3. æå–kept patches
    kept_patches = []
    original_indices = []
    
    for t in range(T):
        indices = torch.where(mask_flat[t])[0]
        original_indices.append(indices)
        kept_patches.append(patches[t][indices])
    
    # ğŸ”¥ ç»Ÿä¸€æ•°é‡
    kept, N_keeps = _unify_kept_patches(kept_patches)
    N_keep = N_keeps.max().item()

    # 4. è®¡ç®—ç›¸ä¼¼åº¦å¹¶æ’åº
    kept_reshaped = kept.reshape(T, N_keep, p*p, C)
    
    if sort_by == 'brightness':
        sort_keys = kept_reshaped.mean(dim=(2, 3))
    elif sort_by == 'color':
        color_mean = kept_reshaped.mean(dim=2)
        sort_keys = (color_mean[..., 0] * 1000 + 
                    color_mean[..., 1] * 100 + 
                    color_mean[..., 2])
    elif sort_by == 'hybrid':
        brightness = kept_reshaped.mean(dim=(2, 3))
        color_mean = kept_reshaped.mean(dim=2)
        sort_keys = (brightness * 10000 + 
                    color_mean[..., 0] * 100 + 
                    color_mean[..., 1] * 10 + 
                    color_mean[..., 2])
    
    # æ’åº
    sorted_kept = []
    sort_orders = []
    
    for t in range(T):
        n_keep = N_keeps[t].item()
        # ğŸ”¥ åªæ’åºæœ‰æ•ˆçš„patches
        valid_keys = sort_keys[t, :n_keep]
        sort_order = torch.argsort(valid_keys)
        
        # å¯¹æœ‰æ•ˆpatchesæ’åº
        sorted_valid = kept[t, :n_keep][sort_order]
        
        # paddingéƒ¨åˆ†ä¿æŒä¸å˜
        sorted_frame = kept[t].clone()
        sorted_frame[:n_keep] = sorted_valid
        
        sorted_kept.append(sorted_frame)
        
        # ä¿å­˜å®Œæ•´çš„sort_orderï¼ˆåŒ…å«paddingç´¢å¼•ï¼‰
        full_sort_order = torch.arange(N_keep, device=kept.device)
        full_sort_order[:n_keep] = sort_order
        sort_orders.append(full_sort_order)
    
    kept = torch.stack(sorted_kept, dim=0)
    sort_orders = torch.stack(sort_orders)

    # 5-6. é‡ç»„
    w_new = max(1, int(math.sqrt(N_keep)))
    h_new = (N_keep + w_new - 1) // w_new
    need_pad = h_new * w_new - N_keep

    if need_pad > 0:
        pad = torch.zeros(T, need_pad, kept.shape[-1],
                        device=pic_tensor.device, dtype=pic_tensor.dtype)
        kept = torch.cat([kept, pad], dim=1)

    squeezed = rearrange(
        kept,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_new, w=w_new, p1=p, p2=p, c=C
    )

    # 7. å…ƒæ•°æ®
    metadata = {
        'method': 'similarity_order',
        'patched_shape': patched_shape,
        'N_keep': N_keep,
        'N_keeps': N_keeps,
        'original_indices': original_indices,
        'sort_orders': sort_orders,
        'region_shape': (H, W),
        'squeezed_shape': (h_new, w_new),
    }

    return squeezed, metadata


def unsqueeze_similarity_order(
    mask=None,
    squeezed_tensor=None,
    metadata=None
):
    """ç›¸ä¼¼åº¦æ’åºçš„unsqueeze - ä¿®å¤ç‰ˆ"""
    if mask is None or metadata is None:
        raise RuntimeError("éœ€è¦maskå’Œmetadata")

    T, C, H_sq, W_sq = squeezed_tensor.shape
    p = 16
    
    patched_shape = metadata['patched_shape']
    N_keeps = metadata['N_keeps']
    original_indices = metadata['original_indices']
    sort_orders = metadata['sort_orders']
    region_shape = metadata['region_shape']

    # 1. æå–patches
    patches = rearrange(
        squeezed_tensor,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p
    )

    # 2. é€†æ’åº
    unsorted_patches = []
    for t in range(T):
        n_keep = N_keeps[t].item()
        
        # åªå¤„ç†æœ‰æ•ˆçš„patches
        valid_patches = patches[t, :n_keep]
        valid_sort_order = sort_orders[t, :n_keep]
        
        # é€†æ’åº
        inverse_order = torch.argsort(valid_sort_order)
        unsorted_valid = valid_patches[inverse_order]
        
        unsorted_patches.append(unsorted_valid)

    # 3. è¿˜åŸåˆ°maskä½ç½®
    h_p, w_p = patched_shape
    full = torch.zeros(T, h_p * w_p, p * p * C,
                      device=squeezed_tensor.device, 
                      dtype=squeezed_tensor.dtype)
    
    mask_flat = mask.reshape(T, h_p * w_p)
    
    for t in range(T):
        full[t, original_indices[t]] = unsorted_patches[t]

    # 4. é‡ç»„
    recon = rearrange(
        full,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_p, w=w_p, p1=p, p2=p, c=C
    )

    return recon[:, :, :region_shape[0], :region_shape[1]]


# ============= æ–¹æ³•3: Hilbertæ›²çº¿ï¼ˆä¿®å¤ç‰ˆï¼‰=============

def hilbert_index(x, y, order=4):
    """è®¡ç®—Hilbertæ›²çº¿ç´¢å¼•"""
    def rot(n, x, y, rx, ry):
        if ry == 0:
            if rx == 1:
                x = n - 1 - x
                y = n - 1 - y
            x, y = y, x
        return x, y
    
    n = 2 ** order
    rx, ry, d = 0, 0, 0
    s = n // 2
    
    while s > 0:
        rx = 1 if (x & s) > 0 else 0
        ry = 1 if (y & s) > 0 else 0
        d += s * s * ((3 * rx) ^ ry)
        x, y = rot(s, x, y, rx, ry)
        s //= 2
    
    return d


def squeeze_hilbert_order(
    patch_size=16,
    mask=None,
    pic_tensor=None
):
    """Hilbertæ›²çº¿æ’åº - ä¿®å¤ç‰ˆ"""
    if mask is None:
        raise RuntimeError("è¯·ç”Ÿæˆmaskä¹‹åå†squeeze")

    T, C, H, W = pic_tensor.shape
    p = patch_size

    padded, (pad_h, pad_w) = _pad_to_multiple(pic_tensor, p)
    h_p = (H + pad_h) // p
    w_p = (W + pad_w) // p
    patched_shape = (h_p, w_p)

    patches = rearrange(
        padded,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p, h=h_p, w=w_p
    )

    mask_flat = mask.reshape(T, h_p * w_p)

    # é¢„è®¡ç®—Hilbertç´¢å¼•
    order = max(3, int(math.ceil(math.log2(max(h_p, w_p)))))
    
    all_hilbert_indices = torch.zeros(h_p * w_p, 
                                      dtype=torch.long, 
                                      device=pic_tensor.device)
    
    for idx in range(h_p * w_p):
        i = idx // w_p
        j = idx % w_p
        all_hilbert_indices[idx] = hilbert_index(j, i, order)

    # æå–å¹¶æ’åº
    kept_patches = []
    original_indices = []
    hilbert_sort_orders = []
    
    for t in range(T):
        indices = torch.where(mask_flat[t])[0]
        original_indices.append(indices)
        
        hilbert_vals = all_hilbert_indices[indices]
        sort_order = torch.argsort(hilbert_vals)
        hilbert_sort_orders.append(sort_order)
        
        kept_patches.append(patches[t][indices][sort_order])
    
    # ç»Ÿä¸€æ•°é‡
    kept, N_keeps = _unify_kept_patches(kept_patches)
    N_keep = N_keeps.max().item()

    # é‡ç»„
    w_new = max(1, int(math.sqrt(N_keep)))
    h_new = (N_keep + w_new - 1) // w_new
    need_pad = h_new * w_new - N_keep

    if need_pad > 0:
        pad = torch.zeros(T, need_pad, kept.shape[-1],
                        device=pic_tensor.device, dtype=pic_tensor.dtype)
        kept = torch.cat([kept, pad], dim=1)

    squeezed = rearrange(
        kept,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_new, w=w_new, p1=p, p2=p, c=C
    )

    metadata = {
        'method': 'hilbert_order',
        'patched_shape': patched_shape,
        'N_keep': N_keep,
        'N_keeps': N_keeps,
        'original_indices': original_indices,
        'hilbert_sort_orders': hilbert_sort_orders,
        'region_shape': (H, W),
        'squeezed_shape': (h_new, w_new),
    }

    return squeezed, metadata


def unsqueeze_hilbert_order(
    mask=None,
    squeezed_tensor=None,
    metadata=None
):
    """Hilbertæ›²çº¿unsqueeze - ä¿®å¤ç‰ˆ"""
    if mask is None or metadata is None:
        raise RuntimeError("éœ€è¦maskå’Œmetadata")

    T, C, H_sq, W_sq = squeezed_tensor.shape
    p = 16
    
    patched_shape = metadata['patched_shape']
    N_keeps = metadata['N_keeps']
    original_indices = metadata['original_indices']
    hilbert_sort_orders = metadata['hilbert_sort_orders']
    region_shape = metadata['region_shape']

    # 1. æå–patches
    patches = rearrange(
        squeezed_tensor,
        't c (h p1) (w p2) -> t (h w) (p1 p2 c)',
        p1=p, p2=p
    )

    # 2. é€†Hilbertæ’åº
    unsorted_patches = []
    for t in range(T):
        n_keep = N_keeps[t].item()
        valid_patches = patches[t, :n_keep]
        inverse_order = torch.argsort(hilbert_sort_orders[t])
        unsorted_patches.append(valid_patches[inverse_order])

    # 3. è¿˜åŸ
    h_p, w_p = patched_shape
    full = torch.zeros(T, h_p * w_p, p * p * C,
                      device=squeezed_tensor.device, 
                      dtype=squeezed_tensor.dtype)
    
    mask_flat = mask.reshape(T, h_p * w_p)
    
    for t in range(T):
        full[t, original_indices[t]] = unsorted_patches[t]

    # 4. é‡ç»„
    recon = rearrange(
        full,
        't (h w) (p1 p2 c) -> t c (h p1) (w p2)',
        h=h_p, w=w_p, p1=p, p2=p, c=C
    )

    return recon[:, :, :region_shape[0], :region_shape[1]]


# ============= è¾¹ç•Œå¹³æ»‘ =============

def smooth_patch_boundaries(squeezed, patch_size=16, blend_width=1):
    """è¾¹ç•Œå¹³æ»‘"""
    if blend_width == 0:
        return squeezed
    
    T, C, H, W = squeezed.shape
    p = patch_size
    b = blend_width
    
    smoothed = squeezed.clone()
    
    # æ°´å¹³è¾¹ç•Œ
    for i in range(p, W, p):
        if i >= W:
            continue
        left_start = max(0, i - b)
        left_end = i
        right_start = i
        right_end = min(W, i + b)
        
        if left_start < left_end and right_start < right_end:
            width = min(b, left_end - left_start, right_end - right_start)
            left = smoothed[:, :, :, left_end-width:left_end]
            right = smoothed[:, :, :, right_start:right_start+width]
            
            alpha = torch.linspace(0, 1, width, device=squeezed.device)
            alpha = alpha.view(1, 1, 1, -1)
            blended = left * (1 - alpha) + right * alpha
            smoothed[:, :, :, left_end-width:left_end] = blended
    
    # å‚ç›´è¾¹ç•Œ
    for i in range(p, H, p):
        if i >= H:
            continue
        top_start = max(0, i - b)
        top_end = i
        bottom_start = i
        bottom_end = min(H, i + b)
        
        if top_start < top_end and bottom_start < bottom_end:
            height = min(b, top_end - top_start, bottom_end - bottom_start)
            top = smoothed[:, :, top_end-height:top_end, :]
            bottom = smoothed[:, :, bottom_start:bottom_start+height, :]
            
            alpha = torch.linspace(0, 1, height, device=squeezed.device)
            alpha = alpha.view(1, 1, -1, 1)
            blended = top * (1 - alpha) + bottom * alpha
            smoothed[:, :, top_end-height:top_end, :] = blended
    
    return smoothed


# ============= ç»Ÿä¸€æ¥å£ =============

def squeeze_unified(
    patch_size=16,
    mask=None,
    pic_tensor=None,
    method='spatial',
    smooth=False,
    smooth_width=1,
    similarity_mode='hybrid'
):
    """ç»Ÿä¸€çš„squeezeæ¥å£"""
    if method == 'spatial':
        squeezed, metadata = squeeze_spatial_order(patch_size, mask, pic_tensor)
    elif method == 'similarity':
        squeezed, metadata = squeeze_similarity_order(
            patch_size, mask, pic_tensor, sort_by=similarity_mode
        )
    elif method == 'hilbert':
        squeezed, metadata = squeeze_hilbert_order(patch_size, mask, pic_tensor)
    else:
        raise ValueError(f"Unknown method: {method}")
    
    if smooth:
        squeezed = smooth_patch_boundaries(squeezed, patch_size, smooth_width)
        metadata['smoothed'] = True
        metadata['smooth_width'] = smooth_width
    else:
        metadata['smoothed'] = False
    
    return squeezed, metadata


def unsqueeze_unified(
    mask=None,
    squeezed_tensor=None,
    metadata=None
):
    """ç»Ÿä¸€çš„unsqueezeæ¥å£"""
    if metadata is None:
        raise RuntimeError("éœ€è¦metadata")
    
    method = metadata['method']
    
    if method == 'spatial_order':
        return unsqueeze_spatial_order(mask, squeezed_tensor, metadata)
    elif method == 'similarity_order':
        return unsqueeze_similarity_order(mask, squeezed_tensor, metadata)
    elif method == 'hilbert_order':
        return unsqueeze_hilbert_order(mask, squeezed_tensor, metadata)
    else:
        raise ValueError(f"Unknown method: {method}")


# ============= æµ‹è¯• =============

def debug_full_pipeline():
    """è°ƒè¯•å®Œæ•´æµç¨‹"""
    print("="*160)
    print("ğŸ§ª è°ƒè¯•Squeeze/Unsqueezeæµç¨‹")
    print("="*160)
    
    # 1. åˆ›å»ºè¾“å…¥
    T, C, H, W = 10, 3, 640, 640
    pic_tensor = torch.rand(T, C, H, W)
    print(f"ğŸ“¥ è¾“å…¥shape: {pic_tensor.shape}")
    
    # 2. ç”Ÿæˆmaskï¼ˆéšæœºï¼Œæ‰€ä»¥æ¯å¸§ä¿ç•™æ•°é‡å¯èƒ½ä¸åŒï¼‰
    patch_size = 16
    h_p = (H + 7) // 16
    w_p = (W + 7) // 16
    
    mask = torch.rand(T, h_p, w_p) > 0.5
    print(f"ğŸ­ Mask shape: {mask.shape}")
    
    # ç»Ÿè®¡æ¯å¸§ä¿ç•™çš„æ•°é‡
    for t in range(min(3, T)):
        n = mask[t].sum().item()
        print(f"   å¸§{t}: {n}/{h_p*w_p} patches ({n/(h_p*w_p)*100:.1f}%)")
    
    # 3. æµ‹è¯•æ‰€æœ‰æ–¹æ³•
    methods = ['spatial', 'similarity', 'hilbert']
    
    for method in methods:
        print(f"\n{'='*160}")
        print(f"ğŸ”§ æµ‹è¯•æ–¹æ³•: {method}")
        print(f"{'='*160}")
        
        try:
            # Squeeze
            squeezed, metadata = squeeze_unified(
                patch_size=patch_size,
                mask=mask,
                pic_tensor=pic_tensor,
                method=method,
                smooth=True
            )
            print(f"âœ… SqueezeæˆåŠŸ: {squeezed.shape}")
            print(f"   N_keeps: {metadata['N_keeps'].tolist()[:3]}... (å‰3å¸§)")
            print(f"   N_keep_max: {metadata['N_keep']}")
            
            # Unsqueeze
            reconstructed = unsqueeze_unified(
                mask=mask,
                squeezed_tensor=squeezed,
                metadata=metadata
            )
            print(f"âœ… UnsqueezeæˆåŠŸ: {reconstructed.shape}")
            
            # éªŒè¯
            if reconstructed.shape == pic_tensor.shape:
                print(f"âœ… å½¢çŠ¶åŒ¹é…ï¼")
            else:
                print(f"âŒ å½¢çŠ¶ä¸åŒ¹é…ï¼")
                
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    debug_full_pipeline()
